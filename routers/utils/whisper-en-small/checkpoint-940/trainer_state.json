{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05319148936170213,
      "grad_norm": 4.302871227264404,
      "learning_rate": 0.0009904255319148935,
      "loss": 5.9538,
      "step": 10
    },
    {
      "epoch": 0.10638297872340426,
      "grad_norm": 6.679190158843994,
      "learning_rate": 0.0009797872340425531,
      "loss": 2.7642,
      "step": 20
    },
    {
      "epoch": 0.1595744680851064,
      "grad_norm": 1.8576124906539917,
      "learning_rate": 0.0009691489361702128,
      "loss": 2.5576,
      "step": 30
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 2.2824113368988037,
      "learning_rate": 0.0009585106382978723,
      "loss": 2.4794,
      "step": 40
    },
    {
      "epoch": 0.26595744680851063,
      "grad_norm": 1.5488133430480957,
      "learning_rate": 0.0009478723404255319,
      "loss": 2.4596,
      "step": 50
    },
    {
      "epoch": 0.3191489361702128,
      "grad_norm": 2.063039779663086,
      "learning_rate": 0.0009372340425531916,
      "loss": 2.4315,
      "step": 60
    },
    {
      "epoch": 0.3723404255319149,
      "grad_norm": 1.0791617631912231,
      "learning_rate": 0.0009265957446808511,
      "loss": 2.4269,
      "step": 70
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.6792577505111694,
      "learning_rate": 0.0009159574468085107,
      "loss": 2.4191,
      "step": 80
    },
    {
      "epoch": 0.4787234042553192,
      "grad_norm": 0.9264859557151794,
      "learning_rate": 0.0009053191489361702,
      "loss": 2.4111,
      "step": 90
    },
    {
      "epoch": 0.5319148936170213,
      "grad_norm": 0.6352989077568054,
      "learning_rate": 0.0008946808510638298,
      "loss": 2.4095,
      "step": 100
    },
    {
      "epoch": 0.5851063829787234,
      "grad_norm": 1.2231426239013672,
      "learning_rate": 0.0008840425531914894,
      "loss": 2.4099,
      "step": 110
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 1.107069730758667,
      "learning_rate": 0.0008734042553191489,
      "loss": 2.405,
      "step": 120
    },
    {
      "epoch": 0.6914893617021277,
      "grad_norm": 0.5808114409446716,
      "learning_rate": 0.0008627659574468085,
      "loss": 2.4007,
      "step": 130
    },
    {
      "epoch": 0.7446808510638298,
      "grad_norm": 0.5617946982383728,
      "learning_rate": 0.0008521276595744681,
      "loss": 2.403,
      "step": 140
    },
    {
      "epoch": 0.7978723404255319,
      "grad_norm": 0.32374727725982666,
      "learning_rate": 0.0008414893617021276,
      "loss": 2.3982,
      "step": 150
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 0.544841468334198,
      "learning_rate": 0.0008308510638297872,
      "loss": 2.3993,
      "step": 160
    },
    {
      "epoch": 0.9042553191489362,
      "grad_norm": 0.3126509189605713,
      "learning_rate": 0.0008202127659574468,
      "loss": 2.3959,
      "step": 170
    },
    {
      "epoch": 0.9574468085106383,
      "grad_norm": 1.3962901830673218,
      "learning_rate": 0.0008095744680851063,
      "loss": 2.4011,
      "step": 180
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.3943817615509033,
      "eval_runtime": 208.4749,
      "eval_samples_per_second": 6.831,
      "eval_steps_per_second": 0.11,
      "step": 188
    },
    {
      "epoch": 1.0106382978723405,
      "grad_norm": 0.4848419427871704,
      "learning_rate": 0.000798936170212766,
      "loss": 2.3985,
      "step": 190
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 0.24989336729049683,
      "learning_rate": 0.0007882978723404256,
      "loss": 2.398,
      "step": 200
    },
    {
      "epoch": 1.1170212765957448,
      "grad_norm": 0.06958097964525223,
      "learning_rate": 0.0007776595744680851,
      "loss": 2.3941,
      "step": 210
    },
    {
      "epoch": 1.1702127659574468,
      "grad_norm": 0.5128059387207031,
      "learning_rate": 0.0007670212765957447,
      "loss": 2.3999,
      "step": 220
    },
    {
      "epoch": 1.2234042553191489,
      "grad_norm": 0.5580361485481262,
      "learning_rate": 0.0007563829787234042,
      "loss": 2.3965,
      "step": 230
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 0.0862182080745697,
      "learning_rate": 0.0007457446808510638,
      "loss": 2.3976,
      "step": 240
    },
    {
      "epoch": 1.3297872340425532,
      "grad_norm": 0.1958296149969101,
      "learning_rate": 0.0007351063829787234,
      "loss": 2.3992,
      "step": 250
    },
    {
      "epoch": 1.3829787234042552,
      "grad_norm": 0.6977757215499878,
      "learning_rate": 0.0007244680851063829,
      "loss": 2.3962,
      "step": 260
    },
    {
      "epoch": 1.4361702127659575,
      "grad_norm": 0.9125342965126038,
      "learning_rate": 0.0007138297872340425,
      "loss": 2.3947,
      "step": 270
    },
    {
      "epoch": 1.4893617021276595,
      "grad_norm": 0.3254528343677521,
      "learning_rate": 0.0007031914893617022,
      "loss": 2.3927,
      "step": 280
    },
    {
      "epoch": 1.5425531914893615,
      "grad_norm": 0.21181270480155945,
      "learning_rate": 0.0006925531914893617,
      "loss": 2.4007,
      "step": 290
    },
    {
      "epoch": 1.5957446808510638,
      "grad_norm": 0.3423188626766205,
      "learning_rate": 0.0006819148936170214,
      "loss": 2.392,
      "step": 300
    },
    {
      "epoch": 1.648936170212766,
      "grad_norm": 0.362384557723999,
      "learning_rate": 0.000671276595744681,
      "loss": 2.3912,
      "step": 310
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 0.42289644479751587,
      "learning_rate": 0.0006606382978723405,
      "loss": 2.3952,
      "step": 320
    },
    {
      "epoch": 1.7553191489361701,
      "grad_norm": 0.3340218961238861,
      "learning_rate": 0.0006500000000000001,
      "loss": 2.3941,
      "step": 330
    },
    {
      "epoch": 1.8085106382978724,
      "grad_norm": 0.39022210240364075,
      "learning_rate": 0.0006393617021276596,
      "loss": 2.3913,
      "step": 340
    },
    {
      "epoch": 1.8617021276595744,
      "grad_norm": 0.4710529148578644,
      "learning_rate": 0.0006287234042553192,
      "loss": 2.3919,
      "step": 350
    },
    {
      "epoch": 1.9148936170212765,
      "grad_norm": 1.0304145812988281,
      "learning_rate": 0.0006180851063829788,
      "loss": 2.3977,
      "step": 360
    },
    {
      "epoch": 1.9680851063829787,
      "grad_norm": 0.6578686833381653,
      "learning_rate": 0.0006074468085106383,
      "loss": 2.3935,
      "step": 370
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.393141746520996,
      "eval_runtime": 208.3344,
      "eval_samples_per_second": 6.835,
      "eval_steps_per_second": 0.11,
      "step": 376
    },
    {
      "epoch": 2.021276595744681,
      "grad_norm": 0.529050350189209,
      "learning_rate": 0.0005968085106382979,
      "loss": 2.3977,
      "step": 380
    },
    {
      "epoch": 2.074468085106383,
      "grad_norm": 0.4152671694755554,
      "learning_rate": 0.0005861702127659575,
      "loss": 2.3905,
      "step": 390
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 0.28076356649398804,
      "learning_rate": 0.000575531914893617,
      "loss": 2.3917,
      "step": 400
    },
    {
      "epoch": 2.1808510638297873,
      "grad_norm": 0.047296613454818726,
      "learning_rate": 0.0005648936170212766,
      "loss": 2.3902,
      "step": 410
    },
    {
      "epoch": 2.2340425531914896,
      "grad_norm": 0.2974308431148529,
      "learning_rate": 0.0005542553191489363,
      "loss": 2.3922,
      "step": 420
    },
    {
      "epoch": 2.2872340425531914,
      "grad_norm": 0.1842995434999466,
      "learning_rate": 0.0005436170212765958,
      "loss": 2.3887,
      "step": 430
    },
    {
      "epoch": 2.3404255319148937,
      "grad_norm": 0.29934728145599365,
      "learning_rate": 0.0005329787234042554,
      "loss": 2.3876,
      "step": 440
    },
    {
      "epoch": 2.393617021276596,
      "grad_norm": 0.4478636682033539,
      "learning_rate": 0.0005223404255319149,
      "loss": 2.389,
      "step": 450
    },
    {
      "epoch": 2.4468085106382977,
      "grad_norm": 0.33724915981292725,
      "learning_rate": 0.0005117021276595745,
      "loss": 2.3998,
      "step": 460
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6693637371063232,
      "learning_rate": 0.0005010638297872341,
      "loss": 2.4192,
      "step": 470
    },
    {
      "epoch": 2.5531914893617023,
      "grad_norm": 0.4131429195404053,
      "learning_rate": 0.0004904255319148936,
      "loss": 2.4027,
      "step": 480
    },
    {
      "epoch": 2.6063829787234045,
      "grad_norm": 0.3079601526260376,
      "learning_rate": 0.0004797872340425532,
      "loss": 2.391,
      "step": 490
    },
    {
      "epoch": 2.6595744680851063,
      "grad_norm": 0.33959856629371643,
      "learning_rate": 0.00046914893617021276,
      "loss": 2.394,
      "step": 500
    },
    {
      "epoch": 2.7127659574468086,
      "grad_norm": 0.09544797986745834,
      "learning_rate": 0.0004585106382978724,
      "loss": 2.3899,
      "step": 510
    },
    {
      "epoch": 2.7659574468085104,
      "grad_norm": 0.3603534698486328,
      "learning_rate": 0.00044787234042553193,
      "loss": 2.3921,
      "step": 520
    },
    {
      "epoch": 2.8191489361702127,
      "grad_norm": 0.4489193260669708,
      "learning_rate": 0.0004372340425531915,
      "loss": 2.393,
      "step": 530
    },
    {
      "epoch": 2.872340425531915,
      "grad_norm": 0.09956042468547821,
      "learning_rate": 0.00042659574468085105,
      "loss": 2.3879,
      "step": 540
    },
    {
      "epoch": 2.925531914893617,
      "grad_norm": 0.05295024812221527,
      "learning_rate": 0.00041595744680851066,
      "loss": 2.3851,
      "step": 550
    },
    {
      "epoch": 2.978723404255319,
      "grad_norm": 0.584729015827179,
      "learning_rate": 0.0004053191489361702,
      "loss": 2.3875,
      "step": 560
    },
    {
      "epoch": 3.0,
      "eval_loss": 2.3904170989990234,
      "eval_runtime": 209.2601,
      "eval_samples_per_second": 6.805,
      "eval_steps_per_second": 0.11,
      "step": 564
    },
    {
      "epoch": 3.0319148936170213,
      "grad_norm": 0.1890253722667694,
      "learning_rate": 0.00039468085106382977,
      "loss": 2.3923,
      "step": 570
    },
    {
      "epoch": 3.0851063829787235,
      "grad_norm": 0.20696794986724854,
      "learning_rate": 0.0003840425531914894,
      "loss": 2.3862,
      "step": 580
    },
    {
      "epoch": 3.1382978723404253,
      "grad_norm": 0.227572962641716,
      "learning_rate": 0.00037340425531914894,
      "loss": 2.3881,
      "step": 590
    },
    {
      "epoch": 3.1914893617021276,
      "grad_norm": 0.24880647659301758,
      "learning_rate": 0.0003627659574468085,
      "loss": 2.3862,
      "step": 600
    },
    {
      "epoch": 3.24468085106383,
      "grad_norm": 0.05852723866701126,
      "learning_rate": 0.00035212765957446805,
      "loss": 2.3883,
      "step": 610
    },
    {
      "epoch": 3.297872340425532,
      "grad_norm": 0.5066128373146057,
      "learning_rate": 0.00034148936170212766,
      "loss": 2.3873,
      "step": 620
    },
    {
      "epoch": 3.351063829787234,
      "grad_norm": 0.905246913433075,
      "learning_rate": 0.0003308510638297872,
      "loss": 2.3899,
      "step": 630
    },
    {
      "epoch": 3.404255319148936,
      "grad_norm": 0.22824062407016754,
      "learning_rate": 0.00032021276595744683,
      "loss": 2.389,
      "step": 640
    },
    {
      "epoch": 3.4574468085106385,
      "grad_norm": 0.04318423196673393,
      "learning_rate": 0.0003095744680851064,
      "loss": 2.3866,
      "step": 650
    },
    {
      "epoch": 3.5106382978723403,
      "grad_norm": 0.16398364305496216,
      "learning_rate": 0.000298936170212766,
      "loss": 2.3857,
      "step": 660
    },
    {
      "epoch": 3.5638297872340425,
      "grad_norm": 0.3849278688430786,
      "learning_rate": 0.00028829787234042556,
      "loss": 2.386,
      "step": 670
    },
    {
      "epoch": 3.617021276595745,
      "grad_norm": 0.06485400348901749,
      "learning_rate": 0.0002776595744680851,
      "loss": 2.3916,
      "step": 680
    },
    {
      "epoch": 3.670212765957447,
      "grad_norm": 0.036745715886354446,
      "learning_rate": 0.0002670212765957447,
      "loss": 2.3909,
      "step": 690
    },
    {
      "epoch": 3.723404255319149,
      "grad_norm": 0.3492838144302368,
      "learning_rate": 0.0002563829787234043,
      "loss": 2.3882,
      "step": 700
    },
    {
      "epoch": 3.776595744680851,
      "grad_norm": 0.14005984365940094,
      "learning_rate": 0.00024574468085106384,
      "loss": 2.3884,
      "step": 710
    },
    {
      "epoch": 3.829787234042553,
      "grad_norm": 0.013754778541624546,
      "learning_rate": 0.00023510638297872342,
      "loss": 2.3873,
      "step": 720
    },
    {
      "epoch": 3.882978723404255,
      "grad_norm": 0.4004470705986023,
      "learning_rate": 0.00022446808510638298,
      "loss": 2.3851,
      "step": 730
    },
    {
      "epoch": 3.9361702127659575,
      "grad_norm": 0.10996203869581223,
      "learning_rate": 0.00021382978723404256,
      "loss": 2.3884,
      "step": 740
    },
    {
      "epoch": 3.9893617021276597,
      "grad_norm": 0.027825480327010155,
      "learning_rate": 0.00020319148936170212,
      "loss": 2.3853,
      "step": 750
    },
    {
      "epoch": 4.0,
      "eval_loss": 2.392094850540161,
      "eval_runtime": 207.7379,
      "eval_samples_per_second": 6.855,
      "eval_steps_per_second": 0.111,
      "step": 752
    },
    {
      "epoch": 4.042553191489362,
      "grad_norm": 0.09351620823144913,
      "learning_rate": 0.0001925531914893617,
      "loss": 2.3837,
      "step": 760
    },
    {
      "epoch": 4.095744680851064,
      "grad_norm": 0.18969212472438812,
      "learning_rate": 0.0001819148936170213,
      "loss": 2.3865,
      "step": 770
    },
    {
      "epoch": 4.148936170212766,
      "grad_norm": 0.1632899045944214,
      "learning_rate": 0.00017127659574468085,
      "loss": 2.3841,
      "step": 780
    },
    {
      "epoch": 4.202127659574468,
      "grad_norm": 0.15542447566986084,
      "learning_rate": 0.00016063829787234043,
      "loss": 2.3847,
      "step": 790
    },
    {
      "epoch": 4.25531914893617,
      "grad_norm": 0.10088388621807098,
      "learning_rate": 0.00015,
      "loss": 2.3837,
      "step": 800
    },
    {
      "epoch": 4.308510638297872,
      "grad_norm": 0.047293808311223984,
      "learning_rate": 0.00013936170212765957,
      "loss": 2.3845,
      "step": 810
    },
    {
      "epoch": 4.361702127659575,
      "grad_norm": 0.02213554084300995,
      "learning_rate": 0.00012872340425531915,
      "loss": 2.3844,
      "step": 820
    },
    {
      "epoch": 4.414893617021277,
      "grad_norm": 0.2733435034751892,
      "learning_rate": 0.00011808510638297873,
      "loss": 2.3871,
      "step": 830
    },
    {
      "epoch": 4.468085106382979,
      "grad_norm": 0.2648926377296448,
      "learning_rate": 0.0001074468085106383,
      "loss": 2.3849,
      "step": 840
    },
    {
      "epoch": 4.5212765957446805,
      "grad_norm": 0.5139914155006409,
      "learning_rate": 9.680851063829788e-05,
      "loss": 2.3857,
      "step": 850
    },
    {
      "epoch": 4.574468085106383,
      "grad_norm": 0.10368595272302628,
      "learning_rate": 8.617021276595745e-05,
      "loss": 2.3847,
      "step": 860
    },
    {
      "epoch": 4.627659574468085,
      "grad_norm": 0.023516064509749413,
      "learning_rate": 7.553191489361702e-05,
      "loss": 2.3851,
      "step": 870
    },
    {
      "epoch": 4.680851063829787,
      "grad_norm": 0.401947021484375,
      "learning_rate": 6.489361702127659e-05,
      "loss": 2.3862,
      "step": 880
    },
    {
      "epoch": 4.73404255319149,
      "grad_norm": 0.006873715668916702,
      "learning_rate": 5.4255319148936176e-05,
      "loss": 2.3838,
      "step": 890
    },
    {
      "epoch": 4.787234042553192,
      "grad_norm": 0.3008139729499817,
      "learning_rate": 4.3617021276595746e-05,
      "loss": 2.3863,
      "step": 900
    },
    {
      "epoch": 4.840425531914894,
      "grad_norm": 0.030629197135567665,
      "learning_rate": 3.2978723404255317e-05,
      "loss": 2.3864,
      "step": 910
    },
    {
      "epoch": 4.8936170212765955,
      "grad_norm": 0.4770301580429077,
      "learning_rate": 2.2340425531914894e-05,
      "loss": 2.387,
      "step": 920
    },
    {
      "epoch": 4.946808510638298,
      "grad_norm": 0.2916393280029297,
      "learning_rate": 1.1702127659574468e-05,
      "loss": 2.3865,
      "step": 930
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.14062628149986267,
      "learning_rate": 1.0638297872340427e-06,
      "loss": 2.3844,
      "step": 940
    }
  ],
  "logging_steps": 10,
  "max_steps": 940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7346114054144e+19,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
